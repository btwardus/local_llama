# What is this?

simple UI for testing local code/chat models

poetry for dependency mangment

- GGUF, new quantization format for CPU
- GPTQ, quantization for GPU

# Models to use, top performing code generation models:
- 73.8% pass@1 HumanEval
https://huggingface.co/Phind/Phind-CodeLlama-34B-v2
https://huggingface.co/TheBloke/Phind-CodeLlama-34B-v2-GGUF
https://huggingface.co/TheBloke/Phind-CodeLlama-34B-v2-GPTQ

- 73.2% pass@1 HumanEval
https://huggingface.co/WizardLM/WizardCoder-Python-34B-V1.0
https://huggingface.co/TheBloke/WizardCoder-Python-34B-V1.0-GGUF
https://huggingface.co/TheBloke/WizardCoder-Python-34B-V1.0-GPTQ


# top model model comparison
https://github.com/emrgnt-cmplxty/zero-shot-replication


https://paperswithcode.com/sota/code-generation-on-humaneval